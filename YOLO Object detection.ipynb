{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO Real-time Object Detection \n",
    "\n",
    "Using a pretrained YOLO model, this algorithm can segment objects ( cars, bicycles, buses..) and people in a given image.\n",
    "This algorithm has multiple use cases: \n",
    "- Autonomous cars \n",
    "- Autonomous trucks\n",
    "- Autonomous ships\n",
    "- Collision avoidance \n",
    "\n",
    "Part 3 contains all the references for this model. Several functions are from Allan Zelener - YAD2K: Yet Another Darknet 2 Keras (https://github.com/allanzelener/YAD2K)\n",
    "\n",
    "Below are the packages and dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Lambda, Conv2D\n",
    "from keras.models import load_model, Model\n",
    "from yad2k.utils.yolo_utils import read_classes, read_anchors, generate_colors, preprocess_image, draw_boxes, scale_boxes, detect\n",
    "from yad2k.models.keras_yolo import yolo_head, yolo_boxes_to_corners, preprocess_true_boxes, yolo_loss, yolo_body, yolo_filter_boxes, yolo_eval\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - YOLO model details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLO (You Only Look Once) is an accurate real-time Object detection alogrithm where you only look once at an image to perform dectection. The algorithm below can detect 60 object classes listed felow \n",
    "\n",
    "<img src=\"nb_images/table 1.JPG\" style=\"width:700px;height:300;\">\n",
    "<caption><center> <u> **Figure 1 </u>:** List of object classes <br> </center></caption>\n",
    "\n",
    "\n",
    "The model relies on 3 steps: \n",
    "- Resize the image to the appropriate input size\n",
    "- Run a Deep convolutional neural network\n",
    "- Filter anchor boxes using score thresholding and intersection over union thresholding     \n",
    "\n",
    "<img src=\"nb_images/figure1.JPG\" style=\"width:900px;height:400;\">\n",
    "<caption><center> <u> **Figure 2 </u>:** Overall model summary<br> </center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we are going to use a pretrained model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Defining classes, anchors and image shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we create the session and define the classes and anchors. We will also input image size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = K.get_session()\n",
    "class_names = read_classes(\"model_data/coco_classes.txt\")\n",
    "anchors = read_anchors(\"model_data/yolo_anchors.txt\")\n",
    "image_shape = (1224., 1632.)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Loading a pretrained model\n",
    "\n",
    "We are going to load an existing pretrained Keras YOLO model whose weights are stored in \"yolo.h5\", which can be downloaded from the official Yolo website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_model = load_model(\"model_data/yolo.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the layers the model contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Convert output of the model to usable bounding box tensors\n",
    "\n",
    "The output of `yolo_model` is a (m, 19, 19, 5, 85) tensor that needs to pass through non-trivial processing and conversion. The following cell does that for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_outputs = yolo_head(yolo_model.output, anchors, len(class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You added `yolo_outputs` to your graph. This set of 4 tensors is ready to be used as input by your `yolo_eval` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 - Filtering boxes\n",
    "\n",
    "`yolo_outputs` gave you all the predicted boxes of `yolo_model` in the correct format. You're now ready to perform filtering and select only the best boxes. Lets now call `yolo_eval`, which you had previously implemented, to do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes, scores, classes = yolo_eval(yolo_outputs, image_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 - Test on images\n",
    "\n",
    "Input images will be placed in images/ directory. The detect function will perform the Object detection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell on the \"test.jpg\" image to verify that your function is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "out_scores, out_boxes, out_classes = detect(sess, \"test1.jpg\", scores, boxes, classes, yolo_model, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run on all files in images/ directory and save it to output/ directory. Images must have same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = [detect(sess, img, scores, boxes, classes, yolo_model, class_names) for img in listdir('images/') if isfile(join('images/', img))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Allan Zelener - YAD2K: Yet Another Darknet 2 Keras (https://github.com/allanzelener/YAD2K)\n",
    "- Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi - You Only Look Once: Unified, Real-Time Object Detection (2015)\n",
    "- Joseph Redmon, Ali Farhadi - YOLO9000: Better, Faster, Stronger (2016)\n",
    "- YOLO website (https://pjreddie.com/darknet/yolo/)"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "convolutional-neural-networks",
   "graded_item_id": "OMdut",
   "launcher_item_id": "bbBOL"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
